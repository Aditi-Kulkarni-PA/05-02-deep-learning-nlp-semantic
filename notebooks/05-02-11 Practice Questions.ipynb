{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26bef15b",
   "metadata": {},
   "source": [
    "**Q1. Which of the following best distinguishes between ‚Äòpolysemy‚Äô and ‚Äòhomonymy‚Äô in lexical semantics?**\n",
    "\n",
    "- Polysemy refers to multiple related meanings of a word, whereas homonymy refers to multiple unrelated meanings sharing the same form. \n",
    "\n",
    "- Polysemy and homonymy are identical; both mean that a word has several unrelated meanings.\n",
    "\n",
    "- Polysemy involves unrelated meanings, whereas homonymy deals with words from different languages.\n",
    "\n",
    "- Polysemy and homonymy both describe words with the same spelling that share the same meaning but differ in usage\n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "\n",
    "Polysemy refers to multiple related meanings of a word, whereas homonymy refers to multiple unrelated meanings sharing the same form.\n",
    "\n",
    "| **Concept**  | **Definition**                                       | **Example**                                    | **Relation Type**                        |\n",
    "| ------------ | ---------------------------------------------------- | ---------------------------------------------- | ---------------------------------------- |\n",
    "| **Polysemy** | When a single word has **multiple related meanings** | *Head* ‚Üí (body part, leader, top of something) | **Related / connected senses**           |\n",
    "| **Homonymy** | When a word form has **multiple unrelated meanings** | *Bank* ‚Üí (river bank, financial bank)          | **Unrelated senses, accidental overlap** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c9f531",
   "metadata": {},
   "source": [
    "**Q2. In semantic role labelling, which word functions as the agent in the sentence ‚ÄòThe chef cooked the meal with care‚Äô?**\n",
    "- The meal\n",
    "- The chef \n",
    "- With care\n",
    "- Cooked \n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "\n",
    "The chef\n",
    "\n",
    "| **Semantic Role**                 | **Word/Phrase** | **Role Description**                                         |\n",
    "| --------------------------------- | --------------- | ------------------------------------------------------------ |\n",
    "| **Agent**                         | **The chef**    | The **doer** of the action ‚Äî the one performing the cooking. |\n",
    "| **Predicate**                     | **cooked**      | The **action** or **verb** that defines the event.           |\n",
    "| **Theme / Patient**               | **the meal**    | The **entity being acted upon** (what is cooked).            |\n",
    "| **Manner / Instrument / Adjunct** | **with care**   | Describes **how** the action was performed (manner).         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5dcebe",
   "metadata": {},
   "source": [
    "**Q3. What principle does the distributional hypothesis in semantics express?**\n",
    "- Semantic similarity is measured by comparing spelling patterns.\n",
    "- Every word has a fixed meaning independent of context.\n",
    "- Words that occur in similar contexts tend to have similar meanings. \n",
    "- Meaning is determined only by dictionary definitions. \n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "\n",
    "Words that occur in similar contexts tend to have similar meanings.\n",
    "\n",
    "| **Concept**                   | **Description**                                                                                                                       | **Example**                                                                            |\n",
    "| ----------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |\n",
    "| **Distributional Hypothesis** | The **meaning of a word** can be inferred from the **contexts** it appears in.                                                        | ‚ÄúDog‚Äù and ‚Äúcat‚Äù often appear near words like *pet, animal, food* ‚Üí ‚Üí similar meanings. |\n",
    "| **Origin**                    | Proposed by linguist **Zellig Harris (1954)** and later popularized by **Firth** ‚Äî *‚ÄúYou shall know a word by the company it keeps.‚Äù* |                                                                                        |\n",
    "| **Used In**                   | Word embeddings (Word2Vec, GloVe, FastText), contextual models (BERT, GPT).                                                           |                                                                                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e843ecf",
   "metadata": {},
   "source": [
    "**Q4. What key advantage does a Conditional Random Field (CRF) model provide for named entity recognition (NER) compared to independent classifiers?**\n",
    "- CRFs enforce valid label sequences by modelling dependencies between consecutive tags. \n",
    "- CRFs ignore surrounding tokens, focusing only on single-word features.\n",
    "- CRFs depend only on fixed gazetteer lists for identifying entities. \n",
    "- CRFs produce random label transitions during training.\n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "\n",
    "CRFs enforce valid label sequences by modelling dependencies between consecutive tags.\n",
    "\n",
    "| **Aspect**            | **Independent Classifiers (e.g., Logistic Regression, SVM)** | **Conditional Random Fields (CRF)**                       |\n",
    "| --------------------- | ------------------------------------------------------------ | --------------------------------------------------------- |\n",
    "| **Prediction Type**   | Predicts each token label **independently**                  | Predicts **entire label sequences** jointly               |\n",
    "| **Context Awareness** | Limited ‚Äî uses only local features                           | Models **dependencies between adjacent tags**             |\n",
    "| **Example (NER)**     | May tag: `New` = B-LOC, `York` = O ‚ùå                         | Learns `New` (B-LOC) ‚Üí `York` (I-LOC) ‚úÖ                   |\n",
    "| **Output Constraint** | Can produce invalid sequences (like `I-ORG` after `O`)       | Ensures **valid tag transitions** (BIO format compliance) |\n",
    "| **Use Case**          | Simpler classification                                       | Sequence labeling tasks (NER, POS tagging, chunking)      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e71290",
   "metadata": {},
   "source": [
    "**Q5. How does WordNet support knowledge-based word sense disambiguation through semantic similarity?**\n",
    "- By training deep neural networks using large unlabelled corpora \n",
    "- By comparing distances between synsets in its hierarchical structure to estimate sense closeness \n",
    "- By using raw word frequency counts without considering their meaning\n",
    "- By ranking senses randomly when glosses overlap \n",
    "\n",
    "‚úÖ Correct answer:\n",
    "\n",
    "By comparing distances between synsets in its hierarchical structure to estimate sense closeness\n",
    "\n",
    "Explanation:\n",
    "WordNet organizes words into synsets (sets of synonyms representing concepts) connected through semantic relations such as hypernymy (is-a), hyponymy, and meronymy.\n",
    "In knowledge-based word sense disambiguation (WSD), the semantic similarity between words or senses is estimated by measuring path distances or conceptual relatedness in this network. The closer two synsets are in the hierarchy, the more semantically similar they are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932f3531",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ecc00",
   "metadata": {},
   "source": [
    "**Q1. Which of the following is a key limitation of the Bag-of-Words (BoW) model in text representation?**\n",
    "- It ignores the order of words and the context between them. \n",
    "- It automatically captures the semantic similarity between words. \n",
    "- It reduces sparsity by learning dense representations. \n",
    "- It can distinguish between 'dog bites man' and 'man bites dog'.\n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "It ignores the order of words and the context between them.\n",
    "\n",
    "Explanation:\n",
    "The Bag-of-Words (BoW) model represents text by counting word occurrences but disregards word order and contextual meaning.\n",
    "For example, ‚Äúdog bites man‚Äù and ‚Äúman bites dog‚Äù would have the same BoW representation ‚Äî even though their meanings are entirely different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e4bccd",
   "metadata": {},
   "source": [
    "**Q2. In a Document‚ÄìTerm Matrix (DTM) generated from a Bag-of-Words representation, what does each cell typically contain?**\n",
    "- The weight of each document in a topic distribution \n",
    "- The probability of a topic occurring in a document\n",
    "- The semantic similarity between two terms\n",
    "- The frequency or count of a specific term in a document\n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "The frequency or count of a specific term in a document\n",
    "\n",
    "Explanation:\n",
    "In a Document‚ÄìTerm Matrix (DTM) derived from the Bag-of-Words model:\n",
    "\n",
    "Rows represent documents,\n",
    "\n",
    "Columns represent terms (words), and\n",
    "\n",
    "Each cell shows how often a particular term appears in a given document ‚Äî i.e., its frequency or count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f237de",
   "metadata": {},
   "source": [
    "**Q3. Which statement best explains how TF-IDF, which stands for Term Frequency-Inverse Document Frequency, improves upon plain Bag-of-Words representation?**\n",
    "- TF-IDF measures syntactic similarity between documents. \n",
    "- TF-IDF assigns higher weights to all words equally to avoid sparsity. \n",
    "- TF-IDF assigns lower weights to very frequent words and highlights words unique to specific documents.\n",
    "- TF-IDF replaces words with dense embeddings using neural models. \n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "TF-IDF assigns lower weights to very frequent words and highlights words unique to specific documents.\n",
    "\n",
    "Explanation:\n",
    "The TF-IDF (Term Frequency‚ÄìInverse Document Frequency) model improves upon the plain Bag-of-Words by reducing the influence of common words (like ‚Äúthe‚Äù, ‚Äúis‚Äù, ‚Äúand‚Äù) and emphasizing informative words that are more unique to each document.\n",
    "\n",
    "TF (Term Frequency): Measures how often a term appears in a document.\n",
    "\n",
    "IDF (Inverse Document Frequency): Penalizes terms that appear in many documents.\n",
    "\n",
    "Together, TF-IDF ensures that words distinctive to a particular document get higher weights, improving the model‚Äôs ability to represent meaningful content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7fc84e",
   "metadata": {},
   "source": [
    "**Q4. What is the key motivation behind using word embeddings such as Word2Vec or GloVe instead of BoW or TF-IDF?**\n",
    "- To replace preprocessing steps such as tokenisation and stopword removal.\n",
    "- To ensure every document has a unique vocabulary without overlap. \n",
    "- To increase sparsity for faster matrix operations.\n",
    "- To learn dense, low-dimensional representations that capture semantic and syntactic relationships between words. \n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "To learn dense, low-dimensional representations that capture semantic and syntactic relationships between words.\n",
    "\n",
    "Explanation:\n",
    "Word embeddings like Word2Vec and GloVe move beyond the sparse, context-agnostic nature of BoW and TF-IDF by learning dense vector representations of words.\n",
    "\n",
    "Words with similar meanings (e.g., king and queen, walk and run) end up close together in the embedding space.\n",
    "\n",
    "These models capture semantic (meaning-based) and syntactic (grammar-based) relationships through training on large text corpora.\n",
    "\n",
    "Thus, embeddings make text representations more compact, meaningful, and effective for downstream NLP tasks like classification, clustering, and topic modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466a30bc",
   "metadata": {},
   "source": [
    "**Q5. In Non-negative Matrix Factorisation (NMF), what is the main goal of the factorisation process?**\n",
    "- To approximate the original document‚Äìterm matrix as the product of two smaller non-negative matrices representing document‚Äìtopic and topic‚Äìterm relations.\n",
    "- To randomly assign topics to words and refine them through probability distributions.\n",
    "- To compress text data by allowing both positive and negative word weights.\n",
    "- To calculate topic probabilities using Dirichlet priors and Bayesian inference. \n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "To approximate the original document‚Äìterm matrix as the product of two smaller non-negative matrices representing document‚Äìtopic and topic‚Äìterm relations.\n",
    "\n",
    "Explanation:\n",
    "In Non-negative Matrix Factorisation (NMF), the goal is to break down a large Document‚ÄìTerm Matrix (V) into two smaller non-negative matrices:\n",
    "\n",
    "W (Document‚ÄìTopic matrix) ‚Äì shows how much each topic contributes to a document.\n",
    "\n",
    "H (Topic‚ÄìTerm matrix) ‚Äì shows how much each word contributes to a topic.\n",
    "\n",
    "Mathematically: V‚âàW√óH\n",
    "\n",
    "The non-negativity constraint makes the results interpretable, since each value can be seen as a degree of association (not a positive/negative weight).\n",
    "This process helps uncover latent topics hidden in large text collections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70c32cf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da1b6d2",
   "metadata": {},
   "source": [
    "**Q1. Which of the following best describes a limitation of classical n-gram language models?**\n",
    "- They automatically learn semantic meaning through embeddings. \n",
    "- They cannot capture long-range dependencies due to fixed-length context.\n",
    "- They encode the sentences as dense, low-dimensional vectors. \n",
    "- They eliminate the need for any smoothing techniques. \n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "They cannot capture long-range dependencies due to fixed-length context.\n",
    "\n",
    "üí° Explanation:\n",
    "Classical n-gram language models rely on the Markov assumption ‚Äî they predict the next word based only on the last N‚Äì1 words. This fixed-size context window prevents them from understanding or remembering relationships between words that are far apart (long-range dependencies).\n",
    "\n",
    "Example: In ‚ÄúThe book that I read yesterday was amazing,‚Äù an n-gram model may fail to link book and was if N is too small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21f01b7",
   "metadata": {},
   "source": [
    "**Q2. What is the main goal of laplace smoothing technique in language modelling?**\n",
    "- To increase the vocabulary size of the corpus.\n",
    "- To assign non-zero probabilities to unseen n-grams and improve generalisation. \n",
    "- To remove low-frequency words from the corpus. \n",
    "- To increase the number of training examples by duplication. \n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "To assign non-zero probabilities to unseen n-grams and improve generalisation.\n",
    "\n",
    "üí° Explanation:\n",
    "Laplace smoothing (also called add-one smoothing) is used in language models to handle the zero-frequency problem ‚Äî when an n-gram never appears in the training data, its probability becomes zero.\n",
    "By adding 1 to every count, Laplace smoothing ensures no n-gram gets zero probability, improving the model‚Äôs ability to generalise to unseen text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319649ae",
   "metadata": {},
   "source": [
    "**Q3. What does a lower perplexity value indicate when evaluating a language model?**\n",
    "- The model uses fewer words in its vocabulary. \n",
    "- The model has memorised the training data without generalising. \n",
    "- The model predicts the test data more confidently and accurately. \n",
    "- The model generates sentences with random probabilities. \n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "The model predicts the test data more confidently and accurately.\n",
    "\n",
    "üí° Explanation:\n",
    "Perplexity measures how well a language model predicts a sample.\n",
    "A lower perplexity means the model assigns higher probabilities to the actual words in the test data ‚Äî i.e., it is **less ‚Äúperplexed‚Äù and more confident in its predictions.**\n",
    "Hence, lower perplexity = better language model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caefee5",
   "metadata": {},
   "source": [
    "**Q4. In classical Natural Language Processing, which statement best describes template-based text generation?**\n",
    "- It fills predefined sentence patterns with slot values using handcrafted rules. \n",
    "- It generates text by sampling from probabilistic word embeddings. \n",
    "- It relies on deep transformer networks for contextual coherence. \n",
    "- It extracts sentences from multiple documents for summarisation.\n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "It fills predefined sentence patterns with slot values using handcrafted rules.\n",
    "\n",
    "üí° Explanation:\n",
    "Template-based text generation is an early NLP technique where sentences are generated using fixed templates or patterns (e.g., ‚ÄúThe [entity] increased by [value] in [year].‚Äù).\n",
    "The system then fills in the blanks (slots) with specific data values.\n",
    "It is simple and interpretable, but lacks flexibility and creativity compared to probabilistic or neural generation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc376fc6",
   "metadata": {},
   "source": [
    "**Q5. How did early statistical machine translation (SMT) systems improve upon rule-based translation methods?**\n",
    "- By learning bilingual phrase alignments and translation probabilities from large corpora \n",
    "- By manually encoding grammar and dictionary rules for each language pair \n",
    "- By relying on template substitution without statistical learning\n",
    "- By using only monolingual text and ignoring parallel data \n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "By learning bilingual phrase alignments and translation probabilities from large corpora\n",
    "\n",
    "üí° Explanation:\n",
    "Early Statistical Machine Translation (SMT) systems replaced rigid, rule-based translation with data-driven learning.\n",
    "They used parallel corpora (aligned sentence pairs) to learn:\n",
    "\n",
    "Word and phrase alignments between source and target languages\n",
    "\n",
    "Translation probabilities and language models to choose the most fluent target sentence\n",
    "\n",
    "This made SMT systems more adaptable and scalable than rule-based approaches, which required extensive manual grammar and dictionary design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aea549d",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b235105",
   "metadata": {},
   "source": [
    "## Graded Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8079315a",
   "metadata": {},
   "source": [
    "**Q1. What role does WordNet play in classical semantic processing?**\n",
    "- It is a statistical model that predicts word sequences in a sentence.\n",
    "- It provides a structured lexical database of synonym sets and semantic relations for representing word meanings. \n",
    "- It generates embeddings through neural networks for semantic similarity. \n",
    "- It is used for grammatical parsing and dependency extraction only. \n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "It provides a structured lexical database of synonym sets and semantic relations for representing word meanings.\n",
    "\n",
    "Explanation:\n",
    "WordNet is a large lexical database of English where words are grouped into sets of synonyms (called synsets), each representing a distinct concept. It also defines semantic relationships like hypernyms (is-a), hyponyms (type-of), meronyms (part-of), and antonyms.\n",
    "\n",
    "This helps classical NLP systems understand word meaning, similarity, and conceptual relationships ‚Äî forming the foundation for many semantic analysis tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328cf869",
   "metadata": {},
   "source": [
    "**Q2. How does the Lesk algorithm determine the correct sense of a word in a sentence?**\n",
    "- It relies on transition probabilities between part-of-speech tags. \n",
    "- It computes cosine similarity between the embedding vectors of the words in a sentence.\n",
    "- It identifies the dictionary sense whose gloss shares the most overlapping words with the surrounding context.\n",
    "- It assigns senses based on the most frequent word usage in the corpus only.\n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "It identifies the dictionary sense whose gloss shares the most overlapping words with the surrounding context.\n",
    "\n",
    "Explanation:\n",
    "\n",
    "The Lesk algorithm is a classic knowledge-based Word Sense Disambiguation (WSD) method.\n",
    "It works by comparing the definition (gloss) of each possible sense of a word (from a dictionary like WordNet) with the context words in the sentence.\n",
    "\n",
    "The sense whose definition shares the most word overlap with the context is chosen as the correct meaning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbf47b1",
   "metadata": {},
   "source": [
    "**Q3. Why are Conditional Random Fields (CRFs) often preferred for sequence labelling tasks such as named entity recognition (NER)?**\n",
    "- Because CRFs model dependencies between adjacent tokens, they ensure valid and globally consistent label sequences.\n",
    "- Because CRFs rely solely on classifying individual tokens without context. \n",
    "- Because CRFs eliminate the need for linguistic features or training data.\n",
    "- Because CRFs randomly assign labels to balance precision and recall. \n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "Because CRFs model dependencies between adjacent tokens, they ensure valid and globally consistent label sequences.\n",
    "\n",
    "Explanation:\n",
    "\n",
    "Conditional Random Fields (CRFs) are powerful for sequence labelling tasks like NER because they don‚Äôt just classify each token in isolation ‚Äî they consider context.\n",
    "\n",
    "They model dependencies between neighbouring labels (e.g., ensuring an ‚ÄúI-ORG‚Äù tag doesn‚Äôt follow a ‚ÄúB-PER‚Äù), producing consistent and context-aware predictions across the entire sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcabbb7",
   "metadata": {},
   "source": [
    "**Q4. Which of the following correctly describes thematic or semantic roles in NLP?**\n",
    "- They are used to detect morphological roots and affixes in words.\n",
    "- They are grammatical categories used only to determine part-of-speech tags.\n",
    "- They assign probabilistic weights to words for topic clustering. \n",
    "- They identify functions such as who performs an action (i.e., the agent) and who receives it (i.e., the patient) within a sentence. \n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "They identify functions such as who performs an action (i.e., the agent) and who receives it (i.e., the patient) within a sentence.\n",
    "\n",
    "Explanation:\n",
    "\n",
    "In Semantic Role Labelling (SRL), words and phrases are analysed to determine their roles in an event or action.\n",
    "For example, in the sentence:\n",
    "- ‚ÄúMary gave John a book.‚Äù\n",
    "- Mary ‚Üí Agent (the doer)\n",
    "- John ‚Üí Recipient (the receiver)\n",
    "- a book ‚Üí Theme (the thing being given)\n",
    "\n",
    "These thematic roles help computers understand who did what to whom, providing deeper semantic understanding beyond syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be6ee02",
   "metadata": {},
   "source": [
    "**Q5. Which of the following best describes rule-based or template-based text generation in classical NLP systems?**\n",
    "- It generates sentences by filling predefined templates with variable values using handcrafted rules. \n",
    "- It produces text by sampling next-word probabilities from large corpora. \n",
    "- It learns sentence structure entirely from neural embeddings without rules.\n",
    "- It summarises existing text by extracting frequent words and sentences. \n",
    "\n",
    "‚úÖ Correct Answer:\n",
    "It generates sentences by filling predefined templates with variable values using handcrafted rules.\n",
    "\n",
    "Explanation:\n",
    "\n",
    "In rule-based or template-based text generation, systems use predefined sentence patterns (templates) and linguistic rules to create grammatically correct outputs.\n",
    "Each template contains slots that are filled with context-specific values.\n",
    "\n",
    "Example:\n",
    "- Template ‚Üí ‚ÄúDear [Name], your order [Order_ID] has been [Status].‚Äù\n",
    "- Output ‚Üí ‚ÄúDear Aditi, your order #4589 has been shipped.‚Äù\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ed16f6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
